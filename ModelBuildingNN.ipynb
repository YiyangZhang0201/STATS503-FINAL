{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86354f1e-3241-4205-9882-0a9de512196e",
   "metadata": {},
   "source": [
    "# Model Building NN\n",
    "\n",
    "Here we will use Nerual Network to do the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3c4a41d-befe-4359-b8b5-ff2d80ca7228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a626d2b-ceb9-4815-b0ae-6af021eb5e64",
   "metadata": {},
   "source": [
    "For stocks from different clusters. We will train a model separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9879883-59a2-46ec-b5d3-78e4c471d5ea",
   "metadata": {},
   "source": [
    "## NN\n",
    "In this notebook, I will build a  Prediction Model with NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87bb0c8d-9e6f-4c47-bddb-fcdabcae230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(net, features, labels):\n",
    "    with torch.no_grad():\n",
    "        mse = criterion(net(features), labels)\n",
    "    return mse.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "267de9c8-4b97-4d52-8c89-bf2b6cc8f6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_features, train_labels, test_features, test_labels,\n",
    "          num_epochs, learning_rate, weight_decay, batch_size):\n",
    "    train_ls, test_ls = [], []\n",
    "    dataset = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "    train_iter = torch.utils.data.DataLoader(dataset, batch_size, shuffle=True)\n",
    "    optimizer = torch.optim.Adam(params=net.parameters(), lr=learning_rate, weight_decay=weight_decay) \n",
    "    net = net.float()\n",
    "    for epoch in range(num_epochs):\n",
    "        for X, y in train_iter:\n",
    "            l = criterion(net(X.float()), y.float())\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "        train_ls.append(mse(net, train_features, train_labels))\n",
    "        if test_labels is not None:\n",
    "            test_ls.append(mse(net, test_features, test_labels))\n",
    "    return train_ls, test_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0052694-c819-4328-8dc1-2506727133db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_k_fold_data(k, i, X, y):\n",
    "    # 返回第i折交叉验证时所需要的训练和验证数据\n",
    "    assert k > 1\n",
    "    fold_size = X.shape[0] // k\n",
    "    X_train, y_train = None, None\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j + 1) * fold_size)\n",
    "        X_part, y_part = X[idx, :], y[idx]\n",
    "        if j == i:\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif X_train is None:\n",
    "            X_train, y_train = X_part, y_part\n",
    "        else:\n",
    "            X_train = torch.cat((X_train, X_part), dim=0)\n",
    "            y_train = torch.cat((y_train, y_part), dim=0)\n",
    "    return X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e08aad8-8263-4726-a40e-ded7ecd4c5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(k, X_train, y_train, num_epochs,\n",
    "           learning_rate, weight_decay, batch_size):\n",
    "    train_l_sum, valid_l_sum = 0, 0\n",
    "    for i in range(k):\n",
    "        data = get_k_fold_data(k, i, X_train, y_train)\n",
    "        net = model\n",
    "        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate,\n",
    "                                   weight_decay, batch_size)\n",
    "        train_l_sum += train_ls[-1]\n",
    "        valid_l_sum += valid_ls[-1]\n",
    "        print('fold %d, train mse %f, valid mse %f' % (i, train_ls[-1], valid_ls[-1]))\n",
    "    return train_l_sum / k, valid_l_sum / k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1a2afb6-073c-4065-ad4e-e6124977338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semilogy(x_vals, y_vals, x_label, y_label, x2_vals=None, y2_vals=None,\n",
    "             legend=None, figsize=(3.5, 2.5)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.semilogy(x_vals, y_vals)\n",
    "    if x2_vals and y2_vals:\n",
    "        plt.semilogy(x2_vals, y2_vals, linestyle=':')\n",
    "        plt.legend(legend)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fb3b6da-89ae-4960-b14f-4d4564130703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0, train mse 0.017802, valid mse 0.015028\n",
      "fold 1, train mse 0.016537, valid mse 0.020090\n",
      "fold 2, train mse 0.017840, valid mse 0.015196\n",
      "fold 3, train mse 0.017772, valid mse 0.015331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [05:33<22:15, 333.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4, train mse 0.016397, valid mse 0.020714\n",
      "For cluster 0\n",
      "5-fold validation: avg train mse 0.017270, avg valid mse 0.017272\n",
      "=======================================\n",
      "fold 0, train mse 0.011414, valid mse 0.007745\n",
      "fold 1, train mse 0.010156, valid mse 0.012776\n",
      "fold 2, train mse 0.010744, valid mse 0.010422\n",
      "fold 3, train mse 0.010186, valid mse 0.012659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [15:25<24:15, 485.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4, train mse 0.010900, valid mse 0.009803\n",
      "For cluster 1\n",
      "5-fold validation: avg train mse 0.010680, avg valid mse 0.010681\n",
      "=======================================\n",
      "fold 0, train mse 0.011111, valid mse 0.009305\n",
      "fold 1, train mse 0.010850, valid mse 0.009894\n",
      "fold 2, train mse 0.010639, valid mse 0.010740\n",
      "fold 3, train mse 0.010604, valid mse 0.010885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [25:35<18:04, 542.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4, train mse 0.010181, valid mse 0.012591\n",
      "For cluster 2\n",
      "5-fold validation: avg train mse 0.010677, avg valid mse 0.010683\n",
      "=======================================\n",
      "fold 0, train mse 0.023156, valid mse 0.015010\n",
      "fold 1, train mse 0.022659, valid mse 0.017186\n",
      "fold 2, train mse 0.020361, valid mse 0.026200\n",
      "fold 3, train mse 0.021114, valid mse 0.023201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [27:49<06:21, 381.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4, train mse 0.020324, valid mse 0.026330\n",
      "For cluster 3\n",
      "5-fold validation: avg train mse 0.021523, avg valid mse 0.021586\n",
      "=======================================\n",
      "fold 0, train mse 0.006421, valid mse 0.005031\n",
      "fold 1, train mse 0.006116, valid mse 0.006304\n",
      "fold 2, train mse 0.006109, valid mse 0.006280\n",
      "fold 3, train mse 0.005668, valid mse 0.008046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [43:22<00:00, 520.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4, train mse 0.006413, valid mse 0.005063\n",
      "For cluster 4\n",
      "5-fold validation: avg train mse 0.006145, avg valid mse 0.006145\n",
      "=======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(5)):\n",
    "    data0 = pd.read_csv(f\"TrainingData/StockType{i}.csv\")\n",
    "    features = data0.drop([\"Target\"], axis=1)\n",
    "    fl = features.columns.to_list()\n",
    "    # standardize the data\n",
    "    target = data0[['Target']]\n",
    "    features = features.apply(lambda x: (x - x.mean()) / (x.std()))\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    target[\"Target\"] = scaler.fit_transform(data0['Target'].values.reshape(-1,1))\n",
    "    # prepare the data\n",
    "    train_features = torch.tensor(features.values, dtype=torch.float)\n",
    "    train_labels = torch.tensor(target.Target.values, dtype=torch.float)\n",
    "    model_sequential = nn.Sequential(\n",
    "          nn.Linear(train_features.shape[1], 128),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(128, 256),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(256, 256),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(256, 256),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(256, 1)\n",
    "        )\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self, features):\n",
    "            super(Net, self).__init__()\n",
    "\n",
    "            self.linear_relu1 = nn.Linear(features, 128)\n",
    "            self.linear_relu2 = nn.Linear(128, 256)\n",
    "            self.linear_relu3 = nn.Linear(256, 256)\n",
    "            self.linear_relu4 = nn.Linear(256, 256)\n",
    "            self.linear5 = nn.Linear(256, 1)\n",
    "        \n",
    "        def forward(self, x):\n",
    "\n",
    "            y_pred = self.linear_relu1(x)\n",
    "            y_pred = nn.functional.relu(y_pred)\n",
    "\n",
    "            y_pred = self.linear_relu2(y_pred)\n",
    "            y_pred = nn.functional.relu(y_pred)\n",
    "\n",
    "            y_pred = self.linear_relu3(y_pred)\n",
    "            y_pred = nn.functional.relu(y_pred)\n",
    "\n",
    "            y_pred = self.linear_relu4(y_pred)\n",
    "            y_pred = nn.functional.relu(y_pred)\n",
    "\n",
    "            y_pred = self.linear5(y_pred)\n",
    "            return y_pred\n",
    "    model = Net(features=train_features.shape[1])\n",
    "\n",
    "    # 使用均方误差作为损失函数\n",
    "    criterion = nn.MSELoss(reduction='mean')\n",
    "    k, num_epochs, lr, weight_decay, batch_size = 5, 50, 0.0005, 0, 64\n",
    "\n",
    "    train_l, valid_l = k_fold(k, train_features, train_labels, num_epochs, lr, weight_decay, batch_size)\n",
    "    print(f\"For cluster {i}\")\n",
    "    print('%d-fold validation: avg train mse %f, avg valid mse %f' % (k, train_l, valid_l))\n",
    "    print(\"=======================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
